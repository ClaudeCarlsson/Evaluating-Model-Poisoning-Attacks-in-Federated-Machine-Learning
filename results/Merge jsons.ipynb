{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d30e16b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17edad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5bcadd",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18a6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(file_path):\n",
    "    \"\"\"\n",
    "    Extract training accuracy and loss + validation accuracy and loss from the raw json files\n",
    "    \n",
    "    From each correlationId there is one json item for each client\n",
    "    \n",
    "    In this functions all items for a specific correlationId are merged to estimate\n",
    "    the performance of the global model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extracting relevant data from each record\n",
    "    extracted_data = []\n",
    "    for record in data:\n",
    "        client_name = record['sender']['name']\n",
    "        correlation_id = record['correlationId']\n",
    "        training_info = json.loads(record['data'])\n",
    "        extracted_data.append({\n",
    "            'client': client_name,\n",
    "            'correlationId': correlation_id,\n",
    "            'training_loss': training_info['training_loss'],\n",
    "            'training_accuracy': training_info['training_accuracy'],\n",
    "            'test_loss': training_info['test_loss'],\n",
    "            'test_accuracy': training_info['test_accuracy']\n",
    "        })\n",
    "\n",
    "    # Creating a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    # Creating a mapping of correlationId to readable round numbers\n",
    "    unique_correlation_ids = df['correlationId'].unique()\n",
    "    round_mapping = {correlation_id: f'Round {i+1}' for i, correlation_id in enumerate(unique_correlation_ids)}\n",
    "\n",
    "    # Applying the mapping to the DataFrame\n",
    "    df['Round'] = df['correlationId'].map(round_mapping)\n",
    "\n",
    "    # Initializing the aggregated data dictionary with lists for each metric\n",
    "    aggregated_data = {\n",
    "        'Round': [],\n",
    "        'training_accuracy': [],\n",
    "        'training_loss': [],\n",
    "        'test_accuracy': [],\n",
    "        'test_loss': []\n",
    "    }\n",
    "\n",
    "    # Aggregating data for each round\n",
    "    for round_label in df['Round'].unique():\n",
    "        round_data = df[df['Round'] == round_label]\n",
    "        aggregated_data['Round'].extend([round_label] * len(round_data))\n",
    "        aggregated_data['training_accuracy'].extend(round_data['training_accuracy'])\n",
    "        aggregated_data['training_loss'].extend(round_data['training_loss'])\n",
    "        aggregated_data['test_accuracy'].extend(round_data['test_accuracy'])\n",
    "        aggregated_data['test_loss'].extend(round_data['test_loss'])\n",
    "\n",
    "    # Converting aggregated data into a DataFrame for plotting\n",
    "    df_aggregated = pd.DataFrame(aggregated_data)\n",
    "\n",
    "    # Create copy of df\n",
    "    df = df_aggregated.copy()\n",
    "\n",
    "    # Group by Round and calculate mean for \n",
    "    df = df.groupby('Round').mean()\n",
    "\n",
    "    # Sort by index\n",
    "    df.index = df.index.astype(str)\n",
    "    numeric_index = df.index.str.extract('(\\d+)')[0].astype(int)\n",
    "    df = df.iloc[numeric_index.argsort()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72562e1",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c1140",
   "metadata": {},
   "source": [
    "First we call the json_to_pdf function to estimate the performance of the global model for each .json file and create a pandas dataframe for each of those. Containing 5 attributes: Round, train_acc, train_loss, val_acc and val_loss\n",
    "\n",
    "\n",
    "Then we calculate the mean for each attribute over all the pandas dataframes that were created with the function above.\n",
    "\n",
    "\n",
    "Finally we save the merged dataframe as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b92edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          training_accuracy  training_loss  test_accuracy  test_loss\n",
      "Round                                                               \n",
      "Round 1            0.122389       2.294455       0.121867   2.294880\n",
      "Round 2            0.151417       2.281256       0.151633   2.281484\n",
      "Round 3            0.189517       2.266066       0.189200   2.266156\n",
      "Round 4            0.230383       2.248210       0.229300   2.248124\n",
      "Round 5            0.269933       2.226629       0.269767   2.226350\n",
      "Round 6            0.307611       2.200446       0.305500   2.200016\n",
      "Round 7            0.345817       2.168743       0.342533   2.168198\n",
      "Round 8            0.385961       2.130873       0.381733   2.130079\n",
      "Round 9            0.425217       2.086286       0.420600   2.085092\n",
      "Round 10           0.458728       2.034281       0.455133   2.032522\n",
      "Round 11           0.489522       1.974421       0.485600   1.971864\n",
      "Round 12           0.517606       1.906608       0.515967   1.903047\n",
      "Round 13           0.546817       1.830894       0.546133   1.826194\n",
      "Round 14           0.576689       1.747488       0.577733   1.741602\n",
      "Round 15           0.609972       1.656995       0.609433   1.649905\n",
      "Round 16           0.641783       1.560612       0.644000   1.552324\n",
      "Round 17           0.669839       1.460487       0.672167   1.451075\n",
      "Round 18           0.694728       1.359812       0.696500   1.349440\n",
      "Round 19           0.716794       1.262198       0.719400   1.251079\n",
      "Round 20           0.735044       1.170791       0.739200   1.159167\n",
      "Round 21           0.750628       1.087722       0.757467   1.075841\n",
      "Round 22           0.764517       1.013950       0.770167   1.002009\n",
      "Round 23           0.775928       0.949371       0.781233   0.937500\n",
      "Round 24           0.785739       0.893229       0.790900   0.881524\n",
      "Round 25           0.793883       0.844508       0.798700   0.833030\n",
      "Round 26           0.801489       0.802129       0.804600   0.790917\n",
      "Round 27           0.807478       0.765092       0.810700   0.754165\n",
      "Round 28           0.813594       0.732534       0.816933   0.721895\n",
      "Round 29           0.819044       0.703731       0.821267   0.693376\n",
      "Round 30           0.823833       0.678084       0.825300   0.668018\n",
      "Round 31           0.828539       0.655101       0.829000   0.645327\n",
      "Round 32           0.832506       0.634380       0.833567   0.624903\n",
      "Round 33           0.835972       0.615630       0.836667   0.606462\n",
      "Round 34           0.839628       0.598647       0.839667   0.589788\n",
      "Round 35           0.842939       0.583217       0.843100   0.574663\n",
      "Round 36           0.845789       0.569142       0.846533   0.560900\n",
      "Round 37           0.848622       0.556254       0.849133   0.548323\n",
      "Round 38           0.851083       0.544413       0.851167   0.536791\n",
      "Round 39           0.853439       0.533500       0.853500   0.526185\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory\n",
    "root = \"Gradient_X100/50_clients_40_rounds\"\n",
    "dir_to_merge = \"10%\"\n",
    "\n",
    "# Define paths\n",
    "path = os.path.join(root, dir_to_merge)\n",
    "file_paths = []\n",
    "for item in os.listdir(path):\n",
    "    if os.path.isfile(os.path.join(path, item)) and not item.endswith('merged.json') and item.endswith('.json'):\n",
    "        file_paths.append(os.path.join(path, item))\n",
    "\n",
    "\n",
    "# Load data from files\n",
    "dfs = []\n",
    "for path in file_paths:\n",
    "    dfs.append(json_to_df(path))  # Each json becomes a df with 4 columns. One for each metric\n",
    "    \n",
    "\n",
    "# Merge rounds\n",
    "merged_df = pd.concat(dfs) # Concatenate the DataFrames\n",
    "merged_df = merged_df.groupby('Round').mean() # Group by 'Round' and calculate the mean\n",
    "\n",
    "\n",
    "# Sort by round (index)\n",
    "merged_df.index = merged_df.index.astype(str)\n",
    "numeric_index = merged_df.index.str.extract('(\\d+)')[0].astype(int)\n",
    "merged_df = merged_df.iloc[numeric_index.argsort()]\n",
    "\n",
    "\n",
    "# View result\n",
    "print(merged_df)\n",
    "\n",
    "\n",
    "# Save\n",
    "json_output = merged_df.to_json(orient='index', indent=4)\n",
    "filename = \"merged.json\"\n",
    "with open(os.path.join(root, dir_to_merge, filename), 'w') as file:\n",
    "    file.write(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30127e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
